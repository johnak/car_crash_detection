{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f4b908-e35a-413e-b00f-c3a2b89d79fd",
      "metadata": {
        "id": "c9f4b908-e35a-413e-b00f-c3a2b89d79fd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4727c6a-6f0f-45c6-abb9-843c94c1d37f",
      "metadata": {
        "id": "d4727c6a-6f0f-45c6-abb9-843c94c1d37f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da7d8a3-1ebb-4529-8d5e-056f7cfddd76",
      "metadata": {
        "id": "5da7d8a3-1ebb-4529-8d5e-056f7cfddd76"
      },
      "outputs": [],
      "source": [
        "# Setup dataset paths\n",
        "train_dir = \"Dataset/Train\"\n",
        "val_dir = \"Dataset/Validation\"\n",
        "test_dir = \"Dataset/Test\"\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/AAI-501-A1 Introduction to Artificial Intelligence/Project/AAI-501_ Dataset'\n",
        "\n",
        "train_dir = dataset_path + '/' + 'Train'\n",
        "val_dir = dataset_path + '/' + 'Validation'\n",
        "test_dir = dataset_path + '/' + 'Test'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VY0ZIBAImKB-"
      },
      "id": "VY0ZIBAImKB-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the images\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))"
      ],
      "metadata": {
        "id": "tudVvXoeqOPm"
      },
      "id": "tudVvXoeqOPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers for classification\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "PWLFsgDaqcFs"
      },
      "id": "PWLFsgDaqcFs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FytDoCkvrZsX"
      },
      "id": "FytDoCkvrZsX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/AAI-501-A1 Introduction to Artificial Intelligence/Project'\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path + \"/\" + \"model_resnet50.h5\")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "3N4DOKm3sVzs"
      },
      "id": "3N4DOKm3sVzs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}