{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
    "\n",
    "model_rms = Model(inputs=base_model.input, outputs=x)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_rms.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12966 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'E://MS_USD//Course 2_AAI-501//FinalProject//Train',  # Replace with the path to your train folder\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accident': 0, 'NonAccident': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4322 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'E://MS_USD//Course 2_AAI-501//FinalProject//Validation',  # Replace with the path to your validation folder\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4323 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'E://MS_USD//Course 2_AAI-501//FinalProject//Test',  # Replace with the path to your validation folder\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "monitor='val_loss', # Monitor validation accuracy\n",
    "# min_delta=0.001, # Minimum change to qualify as an improvement\n",
    "patience=10, # Number of epochs to wait for an improvement\n",
    "verbose=1,\n",
    "# mode='max', # Stop when the quantity monitored has stopped increasing\n",
    "restore_best_weights=True # Restore the weights of the best epoch\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1, \n",
    "    patience=5, \n",
    "    min_lr=0.00001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "        )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2705s\u001b[0m 7s/step - accuracy: 0.7704 - loss: 0.5302 - val_accuracy: 0.3558 - val_loss: 2.4718\n",
      "Epoch 2/5\n",
      "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.7188 - loss: 0.5483 - val_accuracy: 0.5000 - val_loss: 0.8521\n",
      "Epoch 3/5\n",
      "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2755s\u001b[0m 7s/step - accuracy: 0.7895 - loss: 0.4410 - val_accuracy: 0.3637 - val_loss: 2.7428\n",
      "Epoch 4/5\n",
      "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.7188 - loss: 0.3738 - val_accuracy: 0.5000 - val_loss: 0.9395\n",
      "Epoch 5/5\n",
      "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2739s\u001b[0m 7s/step - accuracy: 0.7829 - loss: 0.4327 - val_accuracy: 0.3475 - val_loss: 3.7533\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "trainedHistory_rms = trainModel(model_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('E:\\\\MS_USD\\\\Course 2_AAI-501\\\\FinalProject\\\\RmsPropModel\\\\model_30Epochs_history.pkl', 'wb') as file: \n",
    "    pickle.dump(trainedHistory_rms.history,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rms.save('E:\\\\MS_USD\\\\Course 2_AAI-501\\\\FinalProject\\\\RmsPropModel\\\\rms_model_30Epochs.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
